{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qpteAfvCTAAE",
        "outputId": "f47f8578-b2cb-4f96-cb1b-3722e2d6e10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 10.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=97628b498f0de2fa08ad4562282a71e49c8c84cb7cf60b3a465cf7b4652129cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "torch:  1.10 ; cuda:  cu111\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
            "Collecting detectron2\n",
            "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/detectron2-0.6%2Bcu111-cp37-cp37m-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 718 kB/s \n",
            "\u001b[?25hCollecting black==21.4b2\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.7.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.62.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Collecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.3)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20211023.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Collecting regex>=2020.1.8\n",
            "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 42.2 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 55.2 MB/s \n",
            "\u001b[?25hCollecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.24)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.42.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.1)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20211023-py3-none-any.whl size=60947 sha256=499b3ae7ea9b30aac85bee04d495a56f5c88ca61c909d6f1924400d5b8f7772e\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/98/fc/252d62cab6263c719120e06b28f3378af59b52ce7a20e81852\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=597e75a7a498cda2a18301e2cc7ef58e7f3870dc67e8f441e386f7029bf04f8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, regex, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6+cu111 fvcore-0.1.5.post20211023 hydra-core-1.1.1 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.3.2 regex-2021.11.10 typed-ast-1.5.1 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "drive._mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umWwT4tTTVk_",
        "outputId": "2a96b67c-0ec7-48e3-b26a-c937c63ed466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1nEJ7NTtHcCHNQqUXaoPk55VH3Uwh4QGG',\n",
        "                                    dest_path='./data.zip',\n",
        "                                    unzip=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qutXKS9MTcKU",
        "outputId": "01c144e4-315d-4a37-e3cc-77714dca1419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1nEJ7NTtHcCHNQqUXaoPk55VH3Uwh4QGG into ./data.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "metadata": {
        "id": "h6rxjYaOTiHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = os.listdir('/content/dataset/train')\n",
        "\n",
        "train_data = data_path[:20]\n",
        "val_data = data_path[20:]\n",
        "image_ids = train_data\n",
        "VAL_IMAGE_IDS = val_data\n",
        "os.makedirs('/content/dataset/coco')\n",
        "os.makedirs('/content/dataset/coco/annotation')\n",
        "os.makedirs('/content/dataset/coco/train')\n",
        "os.makedirs('/content/dataset/coco/val')\n",
        "import shutil\n",
        "shutil.move('/content/dataset/test','/content/dataset/coco')\n",
        "\n",
        "for i in train_data:\n",
        "  shutil.move('/content/dataset/train/' + f'{i}' + '/images/' + f'{i}' + '.png','/content/dataset/coco/train')\n",
        "for i in val_data:\n",
        "  shutil.move('/content/dataset/train/' + f'{i}' + '/images/' + f'{i}' + '.png','/content/dataset/coco/val')\n",
        "\n",
        "shutil.move('/content/dataset/test_img_ids.json','/content/dataset/coco/annotation')\n",
        "shutil.copy('/content/drive/MyDrive/Colab/VRDL/hw3/new/train.json','/content/dataset/coco/annotation')\n",
        "shutil.copy('/content/drive/MyDrive/Colab/VRDL/hw3/new/val.json','/content/dataset/coco/annotation')\n",
        "\n",
        "shutil.rmtree('/content/dataset/train')"
      ],
      "metadata": {
        "id": "uMv45bZJTmgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "\n",
        "with open('/content/dataset/coco/annotation/test_img_ids.json') as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "y8Qczfj0UVrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in data:\n",
        "  i['file_name'] = '/content/dataset/coco/test/'+i['file_name']\n",
        "\n",
        "for i in data:\n",
        "  i['image_id'] = i['id'] - 1\n"
      ],
      "metadata": {
        "id": "3D4AWzqmUcgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"nucleus\"]\n",
        "d = 5\n",
        "DatasetCatalog.register(\"nucleus_test\", lambda d=d: data)\n",
        "MetadataCatalog.get(\"nucleus_test\").set(thing_classes=classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hca20pX6ToPv",
        "outputId": "786c92dc-84e5-4960-eb49-c73c4839f795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metadata(name='nucleus_test', thing_classes=['nucleus'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "  \n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "        output_folder = \"coco_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "metadata": {
        "id": "LF6UjDkhUpeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"nucleus_train\",)\n",
        "cfg.DATASETS.TEST = (\"nucleus_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025   # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 3000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = [1000, 2000]        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 32   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "cfg.TEST.EVAL_PERIOD = 100\n",
        "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[8], [16], [32], [64], [128]]\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.SOLVER.GAMMA = 0.05\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/model_final.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.001   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "T59e9titU3OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"nucleus_test\", cfg, False, output_dir=\"./output_test/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"nucleus_test\")\n",
        "inference_on_dataset(predictor.model, val_loader, evaluator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvavZuR9Ure-",
        "outputId": "18bc27a1-ec6b-43b3-e26e-73473ada60a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/14 15:08:59 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[12/14 15:08:59 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'nucleus_test' to COCO format ...\n",
            "\u001b[32m[12/14 15:08:59 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'nucleus_test' to COCO format ...)\n",
            "\u001b[32m[12/14 15:08:59 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[12/14 15:08:59 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 6, #annotations: 0\n",
            "\u001b[32m[12/14 15:08:59 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output_test/nucleus_test_coco_format.json' ...\n",
            "\u001b[32m[12/14 15:08:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[12/14 15:08:59 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/14 15:08:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
            "\u001b[32m[12/14 15:08:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 6 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[12/14 15:09:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.692514 (0.692514 s / iter per device, on 1 devices)\n",
            "\u001b[32m[12/14 15:09:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.346889 s / iter per device, on 1 devices)\n",
            "\u001b[32m[12/14 15:09:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[12/14 15:09:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_test/coco_instances_results.json\n",
            "\u001b[32m[12/14 15:09:03 d2.evaluation.coco_evaluation]: \u001b[0mAnnotations are not available for evaluation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/output_test/coco_instances_results.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for i in data:\n",
        "  i['category_id'] = i['category_id'] + 1,\n",
        "  i['category_id'] = i['category_id'][0]\n",
        "  i['image_id'] = i['image_id'] + 1"
      ],
      "metadata": {
        "id": "JU5iZxAmVHOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy9QLs15VNYk",
        "outputId": "b5b3a310-d536-4e6c-8adb-df6900a9435c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bbox': [443.222412109375,\n",
              "  56.41257858276367,\n",
              "  23.469635009765625,\n",
              "  18.054386138916016],\n",
              " 'category_id': 1,\n",
              " 'image_id': 1,\n",
              " 'score': 0.9736591577529907,\n",
              " 'segmentation': {'counts': 'ge`=6Po05M1N2N100O100000000O10000000000000O100O1O2N2M_^X`0',\n",
              "  'size': [1000, 1000]}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"answer.json\", \"w\") as f:\n",
        "    json.dump(data, f)"
      ],
      "metadata": {
        "id": "GPlPETBRVSzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L0tods1L3Fcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}